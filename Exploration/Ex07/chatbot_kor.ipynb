{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a2b6da6",
   "metadata": {},
   "source": [
    "# 한국어 챗봇 프로젝트\n",
    "\n",
    "  - 공백, 특수문자 전처리\n",
    "  - 토크나이징, 병렬데이터 구축\n",
    "  - 안정적인 학습 수렴\n",
    "  - 맥락에 맞는 한국어 문장 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e28df",
   "metadata": {},
   "source": [
    " ### 적용해볼 만한 것들\n",
    " \n",
    " - 학습 에포크 조정하기\n",
    " - 러닝커브 조정하기\n",
    " - 토크나이저, 임베딩 튜닝\n",
    " - 샘플링 온도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e7f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c125c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"mkdir -p ~/aiffel/transformer_chatbot/data/\")\n",
    "os.system(\"ln -s ~/data/* ~/aiffel/transformer_chatbot/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160e9c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d_path = \"/aiffel/aiffel/transformer_chatbot/data/\"\n",
    "raw_data = pd.read_csv(d_path+\"ChatbotData .csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "80840ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수; 한국어 데이터의 규모가 작으므로 전체 사용\n",
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f287cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거; 한국어 불필요\n",
    "  # sentence = sentence.lower()\n",
    "  # sentence = sentence.strip()\n",
    "\n",
    "  # (유니코드 문자열 \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백으로 대체\n",
    "  # 한글은 유니코드에 포함되어 있고 낱소리만 쓰인 문자열도 포함됨\n",
    "  sentence = re.sub(r'([^\\w?!,])', \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  \n",
    "  # 구두점(punctuation)을 토큰으로 인식하도록 단어와의 사이에 공백\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2e696c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장\n",
    "questions = [preprocess_sentence(s) for s in  raw_data[\"Q\"]]\n",
    "answers = [preprocess_sentence(s) for s in  raw_data[\"A\"]]\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3acec520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 1154번째 질문 샘플: 단둘이는 처음 만나는 날ㅋㅋ\n",
      "전처리 후의 1155번째 답변 샘플: 서로를 아는 좋은 기회가 되겠네요\n",
      "전처리 후의 2105번째 질문 샘플: 보일러 틀고 나갔어ㅠㅠ\n",
      "전처리 후의 2106번째 답변 샘플: 이번달 난방비가 많이 나오겠네요\n"
     ]
    }
   ],
   "source": [
    "# 닿소리이나 홀소리가 따로 쓰인 것도 무사히 포함된 것을 확인\n",
    "print('전처리 후의 {}번째 질문 샘플: {}'.format((i:=1153)+1,questions[i]))\n",
    "print('전처리 후의 {}번째 답변 샘플: {}'.format(i+2, answers[i]))\n",
    "\n",
    "print('전처리 후의 {}번째 질문 샘플: {}'.format((i:=2104)+1,questions[i]))\n",
    "print('전처리 후의 {}번째 답변 샘플: {}'.format(i+2, answers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6b5583c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 6516번째 질문 샘플: 부르고 , 찾고 , 기도해봐도 결국은 이미 끝난 사이다\n",
      "전처리 후의 6516번째 답변 샘플: 언젠간 올 이별이었을까요\n"
     ]
    }
   ],
   "source": [
    "# 따옴표 같은 기타 문장부호 탈락\n",
    "print('전처리 후의 {}번째 질문 샘플: {}'.format((i:=6515)+1,questions[i]))\n",
    "print('전처리 후의 {}번째 답변 샘플: {}'.format(i+1, answers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3e9067dc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'턴', '썩', '뿅', '찌', '듯', '육', '펼', '샜', '학', '뛰', '왓', '톤', '캄', '볼', '곤', '승', '침', '껄', '져', '6', '혐', '퓨', '표', '피', '텁', '뱄', '걸', '트', '골', '와', '누', '축', '봅', '쿨', '험', '깝', '런', 'N', '찢', '딪', '함', '펨', '귈', '낀', '상', '랖', '록', '핑', '광', '거', '합', '나', '롯', '난', '풋', '널', '얇', '진', '위', '버', '촉', '싱', '퉜', '찼', '밌', '묘', '러', '닮', '타', '큰', '찔', '확', '챘', '텀', '옷', '실', '심', '부', '미', '종', '몸', '켓', '홧', '잊', '묵', '질', '님', '짓', '늦', '콧', '괜', '칫', '겟', '능', '죠', '폼', '땜', '령', '냈', '렛', '릅', '뜰', '엠', '맡', '딸', '뒤', '락', '후', '룸', '념', '쿼', 'ㅋ', '멘', '존', '딛', '씁', '쏟', '완', '즘', '딜', '됩', '펭', '갠', '렁', '뀔', '웁', '엇', '써', '롤', '놈', '봐', '양', '복', '녁', '컴', '윗', '컨', 'S', '쩔', '렵', '새', '쉬', '쪘', '댜', '춰', '닝', '짠', '짚', '루', '봤', '중', '톱', ' ', '식', 'ㅜ', '깊', '찝', '헷', '쎌', '차', '독', '여', '쭈', '크', '들', '르', '앗', '께', '옛', '눈', '핏', '소', '남', '박', '꺽', '힙', '급', '꿀', '년', '힌', '눌', '끊', '땠', '구', '흰', '뭘', '노', '된', '렸', '엊', '찹', '매', '빠', '느', '왕', '곱', '덮', '뜩', '룰', '흑', '겼', '프', '껴', '키', '쩡', '닐', '욱', '얽', '혈', '붙', '짼', '극', '서', '쉴', 'ㅎ', '데', '형', '춘', '멀', '호', '햇', '뒀', '면', '닿', '견', '앨', '됨', '휘', '떴', '맙', '낌', '팔', '머', '값', '궁', '씽', '떡', '킁', '빈', '혔', '팅', '췄', '역', '쁨', '윤', '녀', '늘', '눴', '죽', '깰', '팩', '단', '개', '섣', '엉', '줬', '되', '맥', '홀', '먹', '짝', '쪼', '젊', '엔', '시', '꺼', '쿠', '졸', '잦', '드', '랍', '사', '툰', '녕', '붕', '헬', '칠', '망', '흥', '테', '재', '씰', '괘', '땐', '컹', '체', '벋', '층', '낸', '측', '생', '내', '맘', '넓', '납', '안', '랐', '얼', '초', '활', '꾼', '맹', '픈', '받', '콜', '둑', '왼', '놀', '탓', '립', '추', '딱', '섬', '에', '쁠', '짬', '쿵', '돕', '솜', '알', '밀', '줍', '깜', '늪', '닙', '훨', '꿔', '페', '랜', '더', '저', '있', '핸', 'L', '튜', '렴', '뭔', '퇴', '든', '쥐', '디', '넛', '닷', '적', '탱', '빨', '쐬', '륵', '과', '때', '금', 'O', '찜', '뀌', '뻥', '꼼', '플', '틈', '깠', '훌', '회', '귤', '신', '잃', '뽑', '슬', '1', '쾌', '쨌', '엣', '천', '쩍', '얘', '텅', '류', '될', '묻', '벨', '꼰', '짐', '긴', '휴', '온', '쳤', '툴', '말', '탁', '뻑', '귀', '램', '터', '떄', '왤', '음', '습', '없', '9', 'B', '작', '템', '꼴', '2', '뭉', '딩', '비', '보', '밖', '워', '썰', '빡', '맞', '룽', '벅', '름', '졋', '씀', '씩', '봉', '멈', '목', '착', '응', '많', '꿈', '뻤', '탄', '뜨', '올', '링', '훈', '억', '냐', '앙', 'a', '변', '배', '짤', '스', '산', '볍', '쥬', '린', '롱', '삔', '헹', '폭', '럽', '려', '겜', '뢰', '전', '첫', '젔', '민', '반', '옇', '뿍', 'P', '팠', '캬', '웹', '뿐', '숨', 's', '걔', '뒷', '얄', '깅', '잔', '뉴', '간', '의', '팁', '또', '성', '붓', '쳐', '늠', '폐', '펴', '춤', '며', '눅', '퍼', '례', '향', '넷', '귐', '량', '쌓', '땀', '꾹', '꿨', '퐈', '번', '았', '덜', '샌', '주', '끄', '겐', '콕', '맷', '켠', '열', '턱', '냉', '씸', '엽', '젝', '썹', '럿', '냄', '벌', '앉', '맨', 'j', '푹', '래', '됐', '쉽', '밑', '츠', '잼', '규', '픕', '랄', '탐', '글', '득', '투', '겁', '헥', '북', 'ㅊ', '덥', '즙', '넥', '압', '균', '달', '격', '대', '답', '뤄', '늙', '딴', '접', '닳', '캔', '짜', '군', '케', '뽀', '째', '팸', '둠', '놓', '애', '은', '뜻', '줄', '씻', '왠', '섞', '켰', '찮', '떻', '뭐', '맴', '쩝', '랠', '옴', '어', '긋', '덕', '곁', '찍', '불', '촌', '빔', '낙', '정', '판', '콘', '뭣', '5', '씬', '경', '백', '싼', '쫌', '썼', '쑤', '쯤', '였', '밸', '먼', '긍', '조', '갯', '뀐', '슷', '팍', '줘', '뻐', '울', '릇', '본', '너', '낄', '관', '굶', '니', '흠', '맺', '따', '칩', '놨', '겠', '넘', '날', '옵', '갖', '셀', '힘', '협', '챙', '뇌', '길', '찬', '났', '결', '겹', '당', '쏘', '갚', '딘', '움', '참', '꽃', '덩', '벗', '뺏', '잌', '끈', '힐', '촬', '쇠', '릭', '텄', '환', '찐', '킥', '자', '꽂', '권', '춥', '등', '좋', '짧', 'A', '증', '욜', '속', '외', '채', '콤', '탑', '펜', '깍', '뿌', '쩌', '일', '굽', '영', '꽝', '렀', '론', '꼭', '츤', '듦', '낼', '즈', '팀', '희', '킨', '렉', '고', '월', '넣', '네', 'k', '밝', '못', '랭', '쌩', '꿎', '설', '뻘', '닥', '곰', '혹', '렌', '땅', '끼', '꽉', '율', '궜', '뱃', '감', '둔', '뮤', '물', '녔', '랙', '커', '윙', '탕', '꽈', '최', '세', '꾸', '무', '릴', '귄', '수', '막', '떤', '굴', '태', '지', '몽', '도', '통', '밥', '릎', '우', '림', '텔', '검', '준', '킴', '했', '을', '꿧', '츄', '맛', '이', '싸', '찡', '족', '할', '0', '솔', '갑', '잿', '듭', '뽕', '현', '컸', '두', '직', '걱', '닦', '를', '렬', '덧', '픽', '렇', '륜', '각', '딧', '팬', '끗', '른', '흐', '멍', '한', '젖', '쪽', '풀', '닫', '닭', '웽', '쁘', '픔', '익', '껏', '쏠', '품', '만', '법', '헛', '철', '곗', '샐', '옮', '선', '밤', '잇', '었', '듣', '쌈', '낳', '룩', '엘', '취', '총', '동', '약', '믿', '빗', '탈', '헌', '깼', '궈', '그', '웠', '업', '뜁', '겉', '넌', '슴', '둬', '굳', '틱', '얻', '푼', '폰', '렷', '벚', '켜', '씹', '햐', '벴', '액', '효', '토', '마', '옥', '섰', '레', '깃', '평', '깐', '썸', '쓰', '뛴', '빚', '삶', '쌍', '분', '떼', '삿', '튀', '젠', '웬', '쁜', '슨', '흡', '밍', '화', '운', '척', '범', '싹', '쎈', '갇', '바', '챔', '렐', '댈', '쏜', '흘', '몫', '람', '갱', '곳', '블', '티', '뚫', '쭤', '뇨', '건', '쓸', '몬', '별', '션', '유', '컷', '렘', '첩', 'g', '핫', '헤', '싫', '꼈', '8', '댄', '졌', '깬', '쉼', '악', '해', '컥', '뇽', '던', '하', '혀', '똑', '브', '탔', '큼', '옳', 'X', '문', '쌤', '필', '항', '즐', '긁', '원', '잠', '센', '술', '친', '벼', '쭉', '뵈', '욕', '헐', '청', '인', '왔', '낭', '잤', '발', '논', '냅', '밭', '놉', '슈', '뻣', '텨', '빴', '칙', '깔', '랬', '퀴', '텻', '싶', '처', '오', '낚', '꽤', '띵', '병', '섹', '훅', '3', '송', '뚝', '쩐', '않', '낫', '덤', '넹', '으', '뺴', '눠', '씨', '치', '담', '뜸', '뻔', '는', '돌', '갔', '석', '엄', 'n', '씌', '웃', '젤', '녹', '방', '쇼', '쫙', '률', '료', '멤', '포', '점', '꽁', 'o', '밉', '냥', '봇', '삭', '첨', '겨', '큐', '겪', '뭇', '십', '끝', '계', '앱', '다', '입', '텼', '패', '꿩', '임', '연', '혼', '빵', '즉', '흔', '특', '돋', '같', '출', '야', '숭', '킹', '읽', '빌', '핍', '코', '틋', '땡', '굿', '멋', '텍', '죄', '갈', '가', '숍', '벤', '삐', '꿰', '공', '용', '까', '숙', '순', '객', '몰', '력', '기', '쫄', '걷', '랫', '_', '캐', '황', '충', '욌', '높', '밟', '띠', '꼿', '!', '살', '털', '김', '깡', '럴', '곡', '염', 'C', '집', '렜', '옆', '허', '댔', '돈', '벽', '딨', '뎌', '손', '끔', '숏', '란', '색', '헉', '샤', '낮', '숫', '돼', '파', '넋', '놔', '듀', '뺄', '됬', '띄', '섭', '홈', '좀', '게', '뱉', '빙', '혜', '요', '샀', '톡', '로', '명', '베', '띰', '클', '예', '둘', '젯', '랩', '셔', '짰', '카', '잖', '잡', '킬', '푸', '왜', '7', '휨', '택', '떠', '줌', '징', '짱', '덴', '섯', '칼', '뚱', '쳇', '뗄', '삽', '롭', '책', '떨', '쪄', '틀', '빛', '농', '볕', '뷔', '편', '곧', 'c', '걍', 'ㅠ', '릿', '몇', '뒹', '리', '텐', '챗', '삼', '럼', '언', '아', '제', '휙', ',', '봄', '닌', '?', '교', '강', '모', '볶', '엮', '셨', 'D', '툼', '샘', '련', '툭', '근', '칭', '찰', '좁', '메', '엿', '장', '좌', '셥', '괴', '핀', '쓴', '눕', '창', '라', '쌀', '잘', '껀', '획', '뜬', '깨', '콩', '델', '행', '4', '젹', '똥', '듬', '끌', '랑', '절', '앞', '쑥', '웨', '닉', '쟁', '히', '꼬', '댓', '것', '깎', '훔', '쎄', '둥', '퉁', '빼', '몹', '빽', '풍', '끓', '찾', '국', '펑', '뎠'}\n"
     ]
    }
   ],
   "source": [
    "characters = set(c for s in questions + answers for c in s)\n",
    "# print(len(characters))\n",
    "print(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfe37124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20684\n"
     ]
    }
   ],
   "source": [
    "tokens = set(w for s in questions + answers for w in s.split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98dab664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(s.split()) for s in questions + answers)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8cf58d",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b13fd2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "# target_vocab_size는 위의 토큰 수와 대략적으로 비슷한 20000개로 설정 \n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "                                questions + answers, target_vocab_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2d5d3532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [21935]\n",
      "END_TOKEN의 번호 : [21936]\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f90642f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21937\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "30f2c096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8d52451b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ?'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0dd7c09c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'거예요'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ddc99d47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'수 '"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e036c77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5206, 1368, 2623]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [1303, 8721, 5, 6212]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "55b12866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "# 입력 데이타 중 가장 긴 문장의 길이가 22 이므로 22로 설정\n",
    "MAX_LENGTH = 22\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "08b45a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                  tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                  tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5a463986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 21937\n",
      "필터링 후의 질문 샘플 개수: 11821\n",
      "필터링 후의 답변 샘플 개수: 11821\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e3f23106",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b3580",
   "metadata": {},
   "source": [
    "### 모델 정의 및 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a4c1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d71f1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c913e1",
   "metadata": {},
   "source": [
    "### 멀티헤드 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68c263de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8255ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84fc88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e01ec4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fab637a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어 스펙을 입력받아 인코더 레이어를 반환하는 함수\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6640f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e57109a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어 스펙을 입력받아 디코더 레이어를 반환하는 함수\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "275aaa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # create_padding_mask 함수를 인코더 입력에 맵핑\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # create_look_ahead_mask 함수를 디코더 입력에 맵핑\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # create_padding_mask 함수를 두 번째 어텐션 블록입력에 맵핑\n",
    "  # 인코더에서 디코더로 들어오는 벡터들을 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b11d5029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    6670080     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    7197440     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 21937)  5637809     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 19,505,329\n",
      "Trainable params: 19,505,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa46eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "689f4bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "893e594b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9b51037",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b61a6641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0942 - accuracy: 0.2079\n",
      "Epoch 2/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0703 - accuracy: 0.2118\n",
      "Epoch 3/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0555 - accuracy: 0.2142\n",
      "Epoch 4/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0468 - accuracy: 0.2151\n",
      "Epoch 5/30\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.0450 - accuracy: 0.2153\n",
      "Epoch 6/30\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.0408 - accuracy: 0.2161\n",
      "Epoch 7/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0366 - accuracy: 0.2168\n",
      "Epoch 8/30\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.0323 - accuracy: 0.2179\n",
      "Epoch 9/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0285 - accuracy: 0.2184\n",
      "Epoch 10/30\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.0255 - accuracy: 0.2195\n",
      "Epoch 11/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0222 - accuracy: 0.2202\n",
      "Epoch 12/30\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.0205 - accuracy: 0.2205\n",
      "Epoch 13/30\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.0175 - accuracy: 0.2211\n",
      "Epoch 14/30\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.0167 - accuracy: 0.2214\n",
      "Epoch 15/30\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.0154 - accuracy: 0.2217\n",
      "Epoch 16/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0149 - accuracy: 0.2218\n",
      "Epoch 17/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0141 - accuracy: 0.2221\n",
      "Epoch 18/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0129 - accuracy: 0.2223\n",
      "Epoch 19/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0120 - accuracy: 0.2226\n",
      "Epoch 20/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0108 - accuracy: 0.2228\n",
      "Epoch 21/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0116 - accuracy: 0.2228\n",
      "Epoch 22/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0105 - accuracy: 0.2229\n",
      "Epoch 23/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0104 - accuracy: 0.2228\n",
      "Epoch 24/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0098 - accuracy: 0.2230\n",
      "Epoch 25/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0088 - accuracy: 0.2232\n",
      "Epoch 26/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0084 - accuracy: 0.2233\n",
      "Epoch 27/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0089 - accuracy: 0.2232\n",
      "Epoch 28/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0085 - accuracy: 0.2233\n",
      "Epoch 29/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0081 - accuracy: 0.2234\n",
      "Epoch 30/30\n",
      "185/185 [==============================] - 12s 66ms/step - loss: 0.0072 - accuracy: 0.2236\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "abf0bc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "history_dict = history.history\n",
    "loss_values = history_dict[\"loss\"]\n",
    "# val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "axes[0].plot(epochs, loss_values, \"bo\", label=\"Training loss\",)\n",
    "# axes[0].plot(epochs, val_loss_values, \"b\", label=\"Validation loss\",)\n",
    "axes[0].legend()\n",
    "\n",
    "acc = history_dict[\"accuracy\"]\n",
    "# val_acc = history_dict[\"val_accuracy\"]\n",
    "axes[1].plot(epochs, acc, \"bo\", label=\"Training acc\",)\n",
    "# axes[1].plot(epochs, val_acc, \"b\", label=\"Validation acc\",)\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e559ae",
   "metadata": {},
   "source": [
    "### 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7a0d6f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "65f223fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb664d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 어디 있었어?\n",
      "출력 : 이젠 마음의 정리를 기억을 좋겠어요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'이젠 마음의 정리를 기억을 좋겠어요'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('어디 있었어?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "42083d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 완전 대박이네\n",
      "출력 : 마음이 좀 후련해지길 바랄게요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마음이 좀 후련해지길 바랄게요'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"완전 대박이네\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4be8fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 1지망 학교 떨어졌는데 3박 4일 놀러가도 될까?\n",
      "출력 : 위로해 드립니다\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'위로해 드립니다'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"1지망 학교 떨어졌는데 3박 4일 놀러가도 될까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e37bd44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 나 완전 기분 꿀꿀한데 저녁 뭐 먹을까\n",
      "출력 : 아예 알려고 하지 않는 게 편한 거 같아요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아예 알려고 하지 않는 게 편한 거 같아요'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 나 완전 기분 꿀꿀한데 저녁 뭐 먹을까\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0d5865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘나완전기분꿀꿀한데저녁뭐먹을까\n",
      "출력 : 그것만큼 마음 아픈 일도 없겠네요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그것만큼 마음 아픈 일도 없겠네요'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘나완전기분꿀꿀한데저녁뭐먹을까\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6abe5072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘나완전기분꿀꿀\n",
      "출력 : 연애 초기 데이트를 해보면서 극복해보세요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'연애 초기 데이트를 해보면서 극복해보세요'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘나완전기분꿀꿀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "76c1cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 나랑 밥 먹을래?\n",
      "출력 : 저는 좋아요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 좋아요'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 나랑 밥 먹을래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02cefb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 나랑 lunch 먹을래?\n",
      "출력 : 직접 물어보는게 정확할 거예요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보는게 정확할 거예요'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 나랑 lunch 먹을래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04aae8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 나랑 3 먹을래?\n",
      "출력 : 큰 결심이네요 꼭 성공할 거예요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'큰 결심이네요 꼭 성공할 거예요'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 나랑 3 먹을래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a367de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 나랑 PPL 갈래?\n",
      "출력 : 보통 사랑은 그렇죠\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'보통 사랑은 그렇죠'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 나랑 PPL 갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e2143aba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 너 좀 예쁘네\n",
      "출력 : 직접 물어보는 게 좋을 것 같아요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보는 게 좋을 것 같아요'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 너 좀 예쁘네\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "207deae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늴 니 쫌 이쁘네\n",
      "출력 : 좀 더 지켜보는 게 좋겠어요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좀 더 지켜보는 게 좋겠어요'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늴 니 쫌 이쁘네\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99c8cda6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 썸\n",
      "출력 : 귀찮아서 친구랑 하루 종일 연락 안해요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'귀찮아서 친구랑 하루 종일 연락 안해요'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"썸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb225615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
